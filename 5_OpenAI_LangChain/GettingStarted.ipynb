{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af1c6c8",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535278ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\") \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ce87f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000025CEB2763C0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025CEB276E40> root_client=<openai.OpenAI object at 0x0000025CEB2741A0> root_async_client=<openai.AsyncOpenAI object at 0x0000025CEB276BA0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') max_tokens=200\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\", max_tokens=200)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d52663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a category of artificial intelligence that is designed to create new content, such as text, images, music, or other media, often indistinguishable from human-created content. These AI systems are trained on large datasets and use algorithms to generate outputs based on patterns identified during the training process.\n",
      "\n",
      "The most common types of generative AI models include:\n",
      "\n",
      "1. **Generative Adversarial Networks (GANs):** These consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates new data samples, while the discriminator evaluates them. Over time, the generator improves its ability to produce outputs that are indistinguishable from real data to the discriminator.\n",
      "\n",
      "2. **Variational Autoencoders (VAEs):** These models learn to encode input data into a lower-dimensional representation and then reconstruct it back to the original form. This process can also be used to generate new data that is similar to the training set.\n",
      "\n",
      "3. **Transformer-based Models\n"
     ]
    }
   ],
   "source": [
    "#Enter input and get the response\n",
    "result=llm.invoke(\"What is mean by genrative AI?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c00de94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. You will answer the question based on the context provided.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='{context}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Chat prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert AI Engineer. You will answer the question based on the context provided.\"),\n",
    "    (\"user\", \"{context}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcbf85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a suite of tools and services associated with LangChain, a framework designed for developing applications powered by large language models. Langsmith provides features for testing, evaluating, and monitoring applications built with these models. It helps developers ensure their applications are running effectively and can assist in making iterative improvements. The tools offered by Langsmith can include capabilities like logging, error tracking, and performance analysis, which are integral for maintaining robust language model-powered applications.\n"
     ]
    }
   ],
   "source": [
    "##Chain\n",
    "\n",
    "chain=prompt | llm\n",
    "\n",
    "response=chain.invoke({\"context\":\"What is mean by Langsmith?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237dbc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c36416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a suite of tools developed by LangChain that assists in designing, evaluating, and monitoring Language Model (LLM) applications. It allows developers to leverage the capabilities of LangChain for building robust LLM-powered applications. Langsmith tools help in managing the complexities associated with LLMs by providing features for testing, debugging, and optimizing language model performance, thus streamlining the development process for such applications.\n"
     ]
    }
   ],
   "source": [
    "##Stroutput Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt | llm | output_parser\n",
    "\n",
    "response=chain.invoke({\"context\":\"What is mean by Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

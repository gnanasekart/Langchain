{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b5a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "\n",
    "# Control LangChain tracing to LangSmith / LangChain Cloud\n",
    "# The intent here is to disable automatic tracing by default to avoid 403/Forbidden errors\n",
    "# Set to 'false' to disable tracing. Set to 'true' and provide a valid\n",
    "# LANGCHAIN_ENDPOINT and LANGCHAIN_API_KEY to enable tracing to LangChain Cloud.\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'false'  # disable automatic POSTs to LangSmith/LangChain Cloud\n",
    "# Remove any LANGCHAIN_ENDPOINT that would send runs to LangSmith by default (if present)\n",
    "os.environ.pop('LANGCHAIN_ENDPOINT', None)\n",
    "\n",
    "# Keep project/api-key variables (if you later enable tracing) and OpenAI key\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT_DEMO\")\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make smart decisions or predictions.\n"
     ]
    }
   ],
   "source": [
    "# from google import genai\n",
    "\n",
    "# # The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "# client = genai.Client()\n",
    "\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
    "# )\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65403d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(\n",
    "#   base_url=\"https://openrouter.ai/api/v1\",\n",
    "#   api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "# )\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#   extra_headers={\n",
    "#     \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "#     \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "#   },\n",
    "#   extra_body={},\n",
    "#   model=\"openai/gpt-oss-20b:free\",\n",
    "#   messages=[\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": \"What is the meaning of life?\"\n",
    "#     }\n",
    "#   ]\n",
    "# )\n",
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97637f9b",
   "metadata": {},
   "source": [
    "Part 2 : Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f41e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "question = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a cat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2344ad29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7defcce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embd = OpenAIEmbeddings()\n",
    "query_result = embd.embed_query(question)\n",
    "document_result = embd.embed_query(document)\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bb2c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8806977856520077\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_question = [ContentEmbedding(\n",
      "  values=[\n",
      "    0.008137716,\n",
      "    -0.011540056,\n",
      "    0.017296221,\n",
      "    -0.04856275,\n",
      "    0.006153595,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      ")]\n",
      "result_doc = [ContentEmbedding(\n",
      "  values=[\n",
      "    -0.023194725,\n",
      "    0.021841038,\n",
      "    0.018162852,\n",
      "    -0.07353945,\n",
      "    -0.0050972565,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "# Gemini API\n",
    "#  result_question = client.models.embed_content(\n",
    "#         model=\"gemini-embedding-001\",\n",
    "#         contents=question)\n",
    "\n",
    "# result_doc = client.models.embed_content(\n",
    "#         model=\"gemini-embedding-001\",\n",
    "#         contents=document)\n",
    "\n",
    "# print(\"result_question =\", result_question.embeddings)\n",
    "# print(\"result_doc =\", result_doc.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bac91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INDEXING ####\n",
    "\n",
    "# Load blog\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "714b5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e434ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad5a40",
   "metadata": {},
   "source": [
    "Part 3 - Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6adc1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a039045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the newer `invoke` API when available to avoid deprecation warnings\n",
    "query = \"What is Task Decomposition?\"\n",
    "if hasattr(retriever, 'invoke'):\n",
    "    # `invoke` may return a list of documents or a dict depending on implementation\n",
    "    try:\n",
    "        docs = retriever.invoke(query)\n",
    "    except TypeError:\n",
    "        # some implementations expect keyword args\n",
    "        docs = retriever.invoke(texts=[query])\n",
    "else:\n",
    "    # Fallback for older langchain versions\n",
    "    docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c988a990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
